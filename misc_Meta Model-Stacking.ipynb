{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae3a4e2-65ba-4612-84d3-7bbd7b2a4da8",
   "metadata": {},
   "source": [
    "# Meta Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02124656-1dbf-47b9-8b07-645618c7e124",
   "metadata": {},
   "source": [
    "## Imports and custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f9b3a-f01c-46a4-a23e-55dcb0f5f124",
   "metadata": {},
   "source": [
    "First, we import libraries, arrays and list we are going to use for this section.\n",
    "\n",
    "We also redefine a custom function `display_classification_reports_confusion_matrices()` used after GridSearch to display classification report and confusion matrix overall, but also by customer class to assess predictive power for each customer class. `custom_format()` is used to reformat gridsearch results and improve readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d789027-dd52-4e64-8dfd-eb42d8b1b5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import (accuracy_score, make_scorer, f1_score, \n",
    "                             precision_score, recall_score, \n",
    "                             classification_report, ConfusionMatrixDisplay,\n",
    "                             average_precision_score)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433e7ff3-a795-4754-b88e-63bdedd31b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_classification_reports_confusion_matrices(y_pred):\n",
    "    \"\"\"\n",
    "    Takes predictions array as input and display classificaiton report overall and then\n",
    "    Confusion matrices by customer class (rfm_label) that has been previously one hot encoded\n",
    "    \"\"\"\n",
    "    # Create two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n",
    "    fig.subplots_adjust(wspace=0.8)\n",
    "\n",
    "    # Plots standard confusion matrix\n",
    "    ax1.set_title(\"Confusion Matrix (counts)\")\n",
    "    disp1 = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, display_labels=class_names, ax=ax1)\n",
    "    disp1.ax_.set_xticklabels(class_names, rotation=90)\n",
    "    disp1.im_.colorbar.remove()\n",
    "\n",
    "    # Plots normalized confusion matrix\n",
    "    ax2.set_title(\"Confusion Matrix (ratios)\")\n",
    "    disp2 = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test, y_pred, normalize=\"true\", display_labels=class_names, ax=ax2)\n",
    "    disp2.ax_.set_xticklabels(class_names, rotation=90)\n",
    "    disp2.im_.colorbar.remove()\n",
    "\n",
    "    # Get classification report\n",
    "    print(classification_report(y_test, y_pred, output_dict=False, zero_division=1))\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=1)\n",
    "    # Get precision, recall, f1 from report dict\n",
    "    precision = round(report['weighted avg']['precision'], 2)\n",
    "    recall = round(report['weighted avg']['recall'], 2)\n",
    "    f1 = round(report['weighted avg']['f1-score'], 2)\n",
    "    \n",
    "    # Format title\n",
    "    title_formatted = f\"Overall Confusion Matrices\\nprecision={precision} recall={recall} f1={f1}\"\n",
    "    \n",
    "    fig.suptitle(title_formatted, y=1.005)\n",
    "    plt.show()\n",
    "    \n",
    "    # OHE columns matching our rfm_labels\n",
    "    labels_of_interest = ['rfm_label_Good Customers', 'rfm_label_Low Value Customers', 'rfm_label_VIP']\n",
    "\n",
    "    # Find column indices corresponding to OHE rfm_label columns\n",
    "    label_indices = [np.where(columns == label)[0][0] for label in labels_of_interest]\n",
    "\n",
    "    # Iterate over each OHE rfm_label\n",
    "    for i, label in enumerate(labels_of_interest):    \n",
    "        # Find column position of OHE rfm_label\n",
    "        label_index = label_indices[i]\n",
    "\n",
    "        # Find rows of X_test where OHE rfm_label is true\n",
    "        # as data has been processed using scaler\n",
    "        # we select positive instead of equal to 1\n",
    "        rows_of_interest= np.where(X_test[:, label_index] >= 0)\n",
    "\n",
    "        # Select corresponding rows of y_test and y_pred\n",
    "        y_test_subset = y_test[rows_of_interest]\n",
    "        y_pred_subset = y_pred[rows_of_interest]\n",
    "\n",
    "        # Restrict our class_names to only classes in subset\n",
    "        # VIP can only become 5 values, other 6.\n",
    "        classes = np.unique(y_test_subset)\n",
    "        class_names_subset = [class_names[label] for label in classes if label in class_labels]\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "        # Plots standard confusion matrix\n",
    "        axs[0].set_title(\"Confusion Matrix (counts)\")\n",
    "        disp1 = ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test_subset, y_pred_subset, display_labels=class_names_subset, ax=axs[0])\n",
    "        disp1.ax_.set_xticklabels(class_names_subset, rotation=90)\n",
    "        disp1.im_.colorbar.remove()\n",
    "\n",
    "        # Plots normalized confusion matrix\n",
    "        axs[1].set_title(\"Confusion Matrix (ratios)\")\n",
    "        disp2 = ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test_subset, y_pred_subset, normalize=\"true\", display_labels=class_names_subset, ax=axs[1])\n",
    "        disp2.ax_.set_xticklabels(class_names_subset, rotation=90)\n",
    "        disp2.im_.colorbar.remove()\n",
    "\n",
    "        # Get classification report\n",
    "        report = classification_report(y_test_subset, y_pred_subset, output_dict=True, zero_division=1)\n",
    "        # Get precision, recall, f1 from report dict\n",
    "        precision = round(report['weighted avg']['precision'], 2)\n",
    "        recall = round(report['weighted avg']['recall'], 2)\n",
    "        f1 = round(report['weighted avg']['f1-score'], 2)\n",
    "        # Format title\n",
    "        title_formatted = f\"{label}\\nprecision={precision} recall={recall} f1={f1}\"\n",
    "        \n",
    "        # Set figure title to label of interest\n",
    "        fig.subplots_adjust(wspace=0.8)\n",
    "        fig.suptitle(title_formatted, y=1.005)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34863f1-f740-45fc-ab45-29c92098d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom formatting for cv_results\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def custom_format(value, col_name):\n",
    "    if col_name.startswith('param_'):\n",
    "        return value\n",
    "    elif 'time' in col_name:\n",
    "        return round(value, 0)\n",
    "    elif 'mean' in col_name:\n",
    "        return round(value, 3)\n",
    "    elif 'std' in col_name:\n",
    "        return round(value, 4)\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e7409-68e8-4143-9045-242f52cce22d",
   "metadata": {},
   "source": [
    "Now, we load train and test set and also outliers arrays that can be used in outlier removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75480862-d7a5-462c-91e1-7e749028347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [0, 1, 2, 3, 4]\n",
    "class_names = ['Sleeping Dog', 'Low Value Customers', 'Sleeping Beauty', 'Good Customers', 'VIP']\n",
    "colors = ['red', 'orange', 'purple', 'blue', 'green']\n",
    "\n",
    "# Load test set from pickle file\n",
    "with open('testset.pkl', 'rb') as f:\n",
    "    testset = pickle.load(f)\n",
    "X_test, y_test = testset['X_test'], testset['y_test']\n",
    "\n",
    "# Load train set from pickle file\n",
    "with open('trainset_meta.pkl', 'rb') as f:\n",
    "    trainset = pickle.load(f)\n",
    "X_train, y_train = trainset['X_train'], trainset['y_train']\n",
    "\n",
    "with open('columns.pkl', 'rb') as f:\n",
    "    columns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ae11d1-c2ff-4d7c-9c87-40041555d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_name = 'MetaModel.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8cb0bcd-b001-4714-ab63-09b4d02ec381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27300, 83)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5248df7c-ee78-4d7f-8904-a28c24e2a702",
   "metadata": {},
   "source": [
    "Here, we use Robust Scaler to standardize our features before going into gridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cab0e6-02a1-402e-921d-f1f7d8175dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b319388-0763-4228-8b89-52aac5572fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\n",
    "        \"model_name\": \"LogisticRegression\",\n",
    "        \"model\": LogisticRegression(C=0.5,\n",
    "                                     multi_class='multinomial',\n",
    "                                     penalty='l2',\n",
    "                                     solver='saga',\n",
    "                                     max_iter=1000,\n",
    "                                     tol=1e-3),\n",
    "        \"model_filename\": \"LogisticRegression.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"RandomForest\",\n",
    "        \"model\": RandomForestClassifier(n_estimators=300, \n",
    "                                         max_features=30,\n",
    "                                         criterion='gini', \n",
    "                                         max_depth=10),\n",
    "        \"model_filename\": \"RandomForest.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"KNeighbors\",\n",
    "        \"model\": KNeighborsClassifier(n_neighbors=10),\n",
    "        \"model_filename\": \"KNeighbors.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"XGBClassifier\",\n",
    "        \"model\": xgb.XGBClassifier(objective='multi:softmax', \n",
    "                                    eval_metric='mlogloss',\n",
    "                                    max_depth=4,\n",
    "                                    n_estimators=300,\n",
    "                                    learning_rate=0.2,\n",
    "                                    colsample_bytree=0.8),\n",
    "        \"model_filename\": \"XGBClassifier.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"model_name\": \"MLPClassifier\",\n",
    "        \"model\": MLPClassifier(tol=1e-3,\n",
    "                               hidden_layer_sizes=(100,),\n",
    "                               activation='logistic',\n",
    "                               solver='adam',\n",
    "                               alpha=0.01,\n",
    "                               learning_rate='constant',\n",
    "                               max_iter=350),\n",
    "        \"model_filename\": \"MLPClassifier.csv\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0f1657-8ff4-41e9-87f0-052ea82fe430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JoeSanchez\\anaconda3\\envs\\adsml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (350) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model: 3317.14 seconds\n",
      "Best parameters found by GridSearchCV: {'final_estimator__C': 4.6415888336127775, 'final_estimator__multi_class': 'ovr', 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}\n",
      "Accuracy on unseen test data: 61.57%\n"
     ]
    }
   ],
   "source": [
    "# Define base_models\n",
    "base_models = [(model[\"model_name\"], model[\"model\"]) for model in models]\n",
    "\n",
    "# Choose a meta-model\n",
    "meta_model = LogisticRegression(max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Create the StackingClassifier\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=3)\n",
    "\n",
    "# Define the param_grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'final_estimator__C': np.logspace(-2, 2, num=4),\n",
    "        'final_estimator__penalty': ['l1', 'l2'],\n",
    "        'final_estimator__solver': ['liblinear'],\n",
    "        'final_estimator__multi_class': ['ovr']\n",
    "    },\n",
    "    {\n",
    "        'final_estimator__C': np.logspace(-2, 2, num=4),\n",
    "        'final_estimator__penalty': ['l1', 'l2'],\n",
    "        'final_estimator__solver': ['saga'],\n",
    "        'final_estimator__multi_class': ['multinomial']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Use GridSearch to find the best parameters for the meta-model\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=stacking_classifier,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=6,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    "    scoring={\n",
    "        'f1': make_scorer(f1_score, average='weighted'),\n",
    "        'precision': make_scorer(precision_score, average='weighted'),\n",
    "        'recall': make_scorer(recall_score, average='weighted')\n",
    "    },\n",
    "    refit='f1'\n",
    ")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the GridSearchCV on your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print time taken to fit the model\n",
    "print(\"Time taken to fit the model: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "# Print best parameters found by GridSearchCV\n",
    "print(\"Best parameters found by GridSearchCV:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluation on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Accuracy on unseen test data: {:.2f}%\".format(test_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ed9896-d272-4f8e-a43c-3020a8fff5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>param_final_estimator__C</th>\n",
       "      <th>param_final_estimator__multi_class</th>\n",
       "      <th>param_final_estimator__penalty</th>\n",
       "      <th>param_final_estimator__solver</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>std_train_f1</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>std_test_precision</th>\n",
       "      <th>std_train_precision</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>std_train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365.0</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.824</td>\n",
       "      <td>4.641589</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.822</td>\n",
       "      <td>4.641589</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.822</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>361.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>340.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.814</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.215443</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.814</td>\n",
       "      <td>4.641589</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>355.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.815</td>\n",
       "      <td>4.641589</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>365.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.823</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>339.0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.817</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>saga</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_test_f1  mean_train_f1  param_final_estimator__C  \\\n",
       "4           365.0         0.586          0.824                  4.641589   \n",
       "5           360.0         0.586          0.822                  4.641589   \n",
       "7           360.0         0.585          0.822                100.000000   \n",
       "10          361.0         0.585          0.813                  0.215443   \n",
       "14          340.0         0.584          0.814                100.000000   \n",
       "3           362.0         0.584          0.819                  0.215443   \n",
       "12          360.0         0.584          0.814                  4.641589   \n",
       "13          355.0         0.584          0.815                  4.641589   \n",
       "6           365.0         0.584          0.823                100.000000   \n",
       "15          339.0         0.584          0.817                100.000000   \n",
       "\n",
       "   param_final_estimator__multi_class param_final_estimator__penalty  \\\n",
       "4                                 ovr                             l1   \n",
       "5                                 ovr                             l2   \n",
       "7                                 ovr                             l2   \n",
       "10                        multinomial                             l1   \n",
       "14                        multinomial                             l1   \n",
       "3                                 ovr                             l2   \n",
       "12                        multinomial                             l1   \n",
       "13                        multinomial                             l2   \n",
       "6                                 ovr                             l1   \n",
       "15                        multinomial                             l2   \n",
       "\n",
       "   param_final_estimator__solver  std_test_f1  std_train_f1  \\\n",
       "4                      liblinear       0.0038        0.0025   \n",
       "5                      liblinear       0.0039        0.0029   \n",
       "7                      liblinear       0.0043        0.0027   \n",
       "10                          saga       0.0033        0.0033   \n",
       "14                          saga       0.0032        0.0029   \n",
       "3                      liblinear       0.0033        0.0026   \n",
       "12                          saga       0.0027        0.0024   \n",
       "13                          saga       0.0038        0.0036   \n",
       "6                      liblinear       0.0043        0.0023   \n",
       "15                          saga       0.0055        0.0032   \n",
       "\n",
       "    mean_test_precision  mean_train_precision  std_test_precision  \\\n",
       "4                 0.586                 0.828              0.0047   \n",
       "5                 0.587                 0.827              0.0049   \n",
       "7                 0.586                 0.827              0.0054   \n",
       "10                0.585                 0.816              0.0038   \n",
       "14                0.585                 0.818              0.0042   \n",
       "3                 0.585                 0.823              0.0042   \n",
       "12                0.584                 0.818              0.0033   \n",
       "13                0.584                 0.819              0.0047   \n",
       "6                 0.584                 0.827              0.0054   \n",
       "15                0.584                 0.820              0.0061   \n",
       "\n",
       "    std_train_precision  mean_test_recall  mean_train_recall  std_test_recall  \\\n",
       "4                0.0025             0.594              0.826           0.0033   \n",
       "5                0.0029             0.594              0.824           0.0038   \n",
       "7                0.0025             0.594              0.824           0.0040   \n",
       "10               0.0033             0.591              0.815           0.0034   \n",
       "14               0.0030             0.591              0.816           0.0029   \n",
       "3                0.0024             0.593              0.821           0.0032   \n",
       "12               0.0026             0.591              0.816           0.0029   \n",
       "13               0.0037             0.590              0.817           0.0037   \n",
       "6                0.0025             0.593              0.825           0.0038   \n",
       "15               0.0032             0.590              0.818           0.0051   \n",
       "\n",
       "    std_train_recall  \n",
       "4             0.0024  \n",
       "5             0.0028  \n",
       "7             0.0026  \n",
       "10            0.0032  \n",
       "14            0.0028  \n",
       "3             0.0025  \n",
       "12            0.0023  \n",
       "13            0.0035  \n",
       "6             0.0022  \n",
       "15            0.0031  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results.sort_values(\"mean_test_f1\", ascending=False)\n",
    "\n",
    "file_path = os.path.join('gs_results', model_file_name)\n",
    "cv_results.to_csv(file_path, index=False)\n",
    "\n",
    "# Get columns starting with 'param_'\n",
    "param_columns = [col for col in cv_results.columns if col.startswith('param_')]\n",
    "\n",
    "# Create a list of desired column names\n",
    "desired_columns = [\n",
    "    'mean_fit_time',\n",
    "    'mean_test_f1', 'mean_train_f1',\n",
    "    *param_columns, \n",
    "    'std_test_f1', 'std_train_f1',\n",
    "    'mean_test_precision', 'mean_train_precision',\n",
    "    'std_test_precision', 'std_train_precision',\n",
    "    'mean_test_recall', 'mean_train_recall',\n",
    "    'std_test_recall', 'std_train_recall',    \n",
    "]\n",
    "\n",
    "# Apply custom formatting function and select columns\n",
    "cv_results = cv_results.apply(lambda col: col.apply(lambda value: custom_format(value, col.name)))\n",
    "cv_results = cv_results[desired_columns]\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53cabf-22e8-4a69-ae0c-6fac78aa58fb",
   "metadata": {},
   "source": [
    "## Conclusion on Meta Model\n",
    "\n",
    "After evaluating the performance of the meta model in comparison to its base models, we have decided not to continue with it as it did not demonstrate a significant improvement in f1 weighted score. While a meta model can have advantages such as improving interpretability or reducing overfitting, our primary goal was to improve f1 weighted score, and we did not find that to be the case with the meta model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adsml] *",
   "language": "python",
   "name": "conda-env-adsml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
